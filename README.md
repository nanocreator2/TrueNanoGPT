# TrueNanoGPT
Making the complete GPT-2 code (that scores the same as openai's) as small as possible, and without hidden code (pytorch etc), while being max easy to learn/work-on and with the end goal of making the code faster (I'm looking at changing the algorithm's architecture to make that happen).

The file above is the complete GPT-2 code with training code (based on nanoGPT because openai didn't provide us that, and AIs + me also made this repo happen). I ran it on an H200 for a day for 200 USD and while I didn't let it go all the way, the val loss already came down to 3.5269 which is close to OpenAI's GPT-2 Small model as shown on nanoGPT's github page when validated on openwebtext he lists what GPT-2 Small scores there is 3.12. The photo of my training run is attached. Training loss has been removed because it's code that's in the way, we need val loss only. The code at one point even matched another repo's scores exactly nearly when set with other parameter numbers. That really solidifies the code is working. The file I ran on RunPod is above, and the nano version is above also. Both run on GPU. I made it small while ensuring there was no changes to the code (it scores the same in both version), I did this by keeping it running on numpy only (CPU) at first without cupy (GPU), and then with that score, I made the code smaller while checking the score stays the same. The only point at which I made code changes while requiring the score to slightly change is only when changing it to be deterministic (numpy / cupy) and it's only a very tiny change to the very end of the decimal score don't worry, and the name changes to make to the code are few and not the actual algorithm. That's simply because GPU calculates slightly differently. If you want to see that they score the same, simply go to the nano version and you need to change only a few names that's it (ask the AIs online, but I'll say which here once I have time). I already did this recently so I know it'll work.

I made this repo because all of the other repos with this code have it bigger and in many files. I'd like to see visually how the code flows, so it's already difficult just having it in text instead, and that's why it at least must be in 1 file only, and very small code all without making anything confusing either.
